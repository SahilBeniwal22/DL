{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIA0xQtS4BZkkOTTUXVBlc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilBeniwal22/DL/blob/main/housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/Housing.csv')\n",
        "\n",
        "# Preprocess categorical variables\n",
        "# Assuming 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea' are categorical\n",
        "# and 'furnishingstatus' needs one-hot encoding\n",
        "\n",
        "categorical_features = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "one_hot_features = ['furnishingstatus']\n",
        "\n",
        "# Apply label encoding for binary categorical features\n",
        "df[categorical_features] = df[categorical_features].apply(lambda x: x.map({'yes': 1, 'no': 0}))\n",
        "\n",
        "# Apply one-hot encoding for 'furnishingstatus'\n",
        "df = pd.get_dummies(df, columns=one_hot_features)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))  # Output layer for price prediction\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Test MAE: {mae}')\n",
        "\n",
        "# Predict house prices\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGmB_NfG-pfW",
        "outputId": "0fe2f538-2571-40f8-cc9c-15c328da24d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 3s 54ms/step - loss: 25516159533056.0000 - mae: 4730274.5000 - val_loss: 22728002240512.0000 - val_mae: 4494953.5000\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 25516140658688.0000 - mae: 4730273.5000 - val_loss: 22727974977536.0000 - val_mae: 4494950.5000\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 25516098715648.0000 - mae: 4730269.0000 - val_loss: 22727918354432.0000 - val_mae: 4494944.5000\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 25516006440960.0000 - mae: 4730260.0000 - val_loss: 22727794622464.0000 - val_mae: 4494931.5000\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 25515803017216.0000 - mae: 4730240.5000 - val_loss: 22727538769920.0000 - val_mae: 4494905.5000\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 25515406655488.0000 - mae: 4730203.0000 - val_loss: 22727073202176.0000 - val_mae: 4494858.0000\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 25514693623808.0000 - mae: 4730135.5000 - val_loss: 22726263701504.0000 - val_mae: 4494778.0000\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 25513447915520.0000 - mae: 4730022.5000 - val_loss: 22724957175808.0000 - val_mae: 4494649.5000\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 25511461912576.0000 - mae: 4729841.5000 - val_loss: 22722876801024.0000 - val_mae: 4494447.5000\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 25508249075712.0000 - mae: 4729558.0000 - val_loss: 22719854804992.0000 - val_mae: 4494155.0000\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 25503694061568.0000 - mae: 4729152.5000 - val_loss: 22715438202880.0000 - val_mae: 4493733.0000\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25496945426432.0000 - mae: 4728564.0000 - val_loss: 22709329199104.0000 - val_mae: 4493154.0000\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 25487657140224.0000 - mae: 4727760.5000 - val_loss: 22700951076864.0000 - val_mae: 4492363.5000\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 25475248291840.0000 - mae: 4726688.5000 - val_loss: 22689745993728.0000 - val_mae: 4491315.0000\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 25458213126144.0000 - mae: 4725235.0000 - val_loss: 22675122552832.0000 - val_mae: 4489954.0000\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25436799107072.0000 - mae: 4723384.0000 - val_loss: 22656556466176.0000 - val_mae: 4488235.0000\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25409557102592.0000 - mae: 4721088.5000 - val_loss: 22634301489152.0000 - val_mae: 4486167.0000\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 25377495842816.0000 - mae: 4718331.0000 - val_loss: 22605750861824.0000 - val_mae: 4483536.5000\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25333908635648.0000 - mae: 4714686.0000 - val_loss: 22571974131712.0000 - val_mae: 4480417.5000\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25284747198464.0000 - mae: 4710458.0000 - val_loss: 22529617952768.0000 - val_mae: 4476532.5000\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 25223455834112.0000 - mae: 4705325.5000 - val_loss: 22481366679552.0000 - val_mae: 4472088.0000\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25151588532224.0000 - mae: 4699287.0000 - val_loss: 22424936513536.0000 - val_mae: 4466891.5000\n",
            "Epoch 23/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25070370029568.0000 - mae: 4692415.5000 - val_loss: 22357588574208.0000 - val_mae: 4460710.0000\n",
            "Epoch 24/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24972416253952.0000 - mae: 4684122.5000 - val_loss: 22279211712512.0000 - val_mae: 4453499.0000\n",
            "Epoch 25/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24856959647744.0000 - mae: 4674386.5000 - val_loss: 22190084849664.0000 - val_mae: 4445284.5000\n",
            "Epoch 26/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24728295178240.0000 - mae: 4663439.0000 - val_loss: 22084942036992.0000 - val_mae: 4435611.0000\n",
            "Epoch 27/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24572659236864.0000 - mae: 4650304.0000 - val_loss: 21970594824192.0000 - val_mae: 4425030.5000\n",
            "Epoch 28/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24403106594816.0000 - mae: 4636108.5000 - val_loss: 21838918844416.0000 - val_mae: 4412864.0000\n",
            "Epoch 29/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24214639738880.0000 - mae: 4619855.5000 - val_loss: 21692317433856.0000 - val_mae: 4399254.5000\n",
            "Epoch 30/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24004108746752.0000 - mae: 4601812.0000 - val_loss: 21527219142656.0000 - val_mae: 4383875.5000\n",
            "Epoch 31/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23774533517312.0000 - mae: 4582059.5000 - val_loss: 21348770381824.0000 - val_mae: 4367142.5000\n",
            "Epoch 32/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23518062313472.0000 - mae: 4559584.5000 - val_loss: 21156339908608.0000 - val_mae: 4348934.5000\n",
            "Epoch 33/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23239180943360.0000 - mae: 4535432.0000 - val_loss: 20949510389760.0000 - val_mae: 4329221.0000\n",
            "Epoch 34/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 22936511578112.0000 - mae: 4508919.5000 - val_loss: 20715354980352.0000 - val_mae: 4306839.5000\n",
            "Epoch 35/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 22610035343360.0000 - mae: 4479700.5000 - val_loss: 20464057450496.0000 - val_mae: 4282532.5000\n",
            "Epoch 36/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 22250753359872.0000 - mae: 4447611.0000 - val_loss: 20196012064768.0000 - val_mae: 4256381.0000\n",
            "Epoch 37/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 21861022826496.0000 - mae: 4412386.0000 - val_loss: 19902830215168.0000 - val_mae: 4227443.0000\n",
            "Epoch 38/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 21456171827200.0000 - mae: 4374810.0000 - val_loss: 19587707961344.0000 - val_mae: 4196066.0000\n",
            "Epoch 39/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 21022604525568.0000 - mae: 4334311.5000 - val_loss: 19258148913152.0000 - val_mae: 4162767.2500\n",
            "Epoch 40/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20556885786624.0000 - mae: 4290624.5000 - val_loss: 18911588253696.0000 - val_mae: 4127255.2500\n",
            "Epoch 41/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20072366080000.0000 - mae: 4244082.5000 - val_loss: 18547193413632.0000 - val_mae: 4089256.0000\n",
            "Epoch 42/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19580109979648.0000 - mae: 4195359.5000 - val_loss: 18158922498048.0000 - val_mae: 4048143.0000\n",
            "Epoch 43/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19028980531200.0000 - mae: 4140653.5000 - val_loss: 17765146558464.0000 - val_mae: 4005560.7500\n",
            "Epoch 44/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 18491604205568.0000 - mae: 4084548.0000 - val_loss: 17337909510144.0000 - val_mae: 3958567.7500\n",
            "Epoch 45/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 17912156913664.0000 - mae: 4025335.2500 - val_loss: 16906165682176.0000 - val_mae: 3909906.2500\n",
            "Epoch 46/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 17336249614336.0000 - mae: 3962192.0000 - val_loss: 16462359035904.0000 - val_mae: 3858702.2500\n",
            "Epoch 47/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 16732124086272.0000 - mae: 3895519.7500 - val_loss: 16008507031552.0000 - val_mae: 3804957.0000\n",
            "Epoch 48/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 16116872118272.0000 - mae: 3825492.0000 - val_loss: 15548073115648.0000 - val_mae: 3749065.0000\n",
            "Epoch 49/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15505493590016.0000 - mae: 3752274.0000 - val_loss: 15076493885440.0000 - val_mae: 3689964.0000\n",
            "Epoch 50/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 14881407369216.0000 - mae: 3677448.5000 - val_loss: 14601377808384.0000 - val_mae: 3628501.7500\n",
            "Epoch 51/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 14266224607232.0000 - mae: 3599420.7500 - val_loss: 14130006196224.0000 - val_mae: 3565501.5000\n",
            "Epoch 52/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 13642843029504.0000 - mae: 3517412.0000 - val_loss: 13654734929920.0000 - val_mae: 3499635.0000\n",
            "Epoch 53/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 13042599329792.0000 - mae: 3433606.5000 - val_loss: 13187978100736.0000 - val_mae: 3432370.5000\n",
            "Epoch 54/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 12466986680320.0000 - mae: 3350331.7500 - val_loss: 12711764164608.0000 - val_mae: 3361219.0000\n",
            "Epoch 55/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 11878173507584.0000 - mae: 3261942.7500 - val_loss: 12259551084544.0000 - val_mae: 3290379.2500\n",
            "Epoch 56/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 11325564518400.0000 - mae: 3174874.7500 - val_loss: 11815894384640.0000 - val_mae: 3217683.7500\n",
            "Epoch 57/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 10784740474880.0000 - mae: 3086733.7500 - val_loss: 11392876806144.0000 - val_mae: 3145473.7500\n",
            "Epoch 58/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 10295623811072.0000 - mae: 3003605.5000 - val_loss: 10973224108032.0000 - val_mae: 3070013.5000\n",
            "Epoch 59/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 9815802773504.0000 - mae: 2919612.5000 - val_loss: 10586914029568.0000 - val_mae: 2996800.2500\n",
            "Epoch 60/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 9373650780160.0000 - mae: 2840517.5000 - val_loss: 10223175598080.0000 - val_mae: 2924568.2500\n",
            "Epoch 61/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 8974901444608.0000 - mae: 2766008.2500 - val_loss: 9886551244800.0000 - val_mae: 2854551.2500\n",
            "Epoch 62/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 8607854231552.0000 - mae: 2697107.5000 - val_loss: 9570120368128.0000 - val_mae: 2785630.5000\n",
            "Epoch 63/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 8270465466368.0000 - mae: 2632612.2500 - val_loss: 9261515014144.0000 - val_mae: 2716855.7500\n",
            "Epoch 64/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 7948590907392.0000 - mae: 2569707.7500 - val_loss: 8989964238848.0000 - val_mae: 2663276.7500\n",
            "Epoch 65/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 7677426532352.0000 - mae: 2516779.2500 - val_loss: 8724929314816.0000 - val_mae: 2620211.2500\n",
            "Epoch 66/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 7411556417536.0000 - mae: 2465548.0000 - val_loss: 8478337269760.0000 - val_mae: 2578675.0000\n",
            "Epoch 67/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 7173819596800.0000 - mae: 2414829.5000 - val_loss: 8246824271872.0000 - val_mae: 2537577.2500\n",
            "Epoch 68/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6954271899648.0000 - mae: 2368727.2500 - val_loss: 8037859852288.0000 - val_mae: 2501129.2500\n",
            "Epoch 69/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6761624371200.0000 - mae: 2328633.2500 - val_loss: 7838692278272.0000 - val_mae: 2469068.7500\n",
            "Epoch 70/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 6584333238272.0000 - mae: 2291078.7500 - val_loss: 7655289520128.0000 - val_mae: 2437709.7500\n",
            "Epoch 71/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6415674507264.0000 - mae: 2255702.2500 - val_loss: 7482252460032.0000 - val_mae: 2409711.2500\n",
            "Epoch 72/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6261804892160.0000 - mae: 2225003.2500 - val_loss: 7317750284288.0000 - val_mae: 2383291.2500\n",
            "Epoch 73/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 6120885190656.0000 - mae: 2194969.0000 - val_loss: 7160943083520.0000 - val_mae: 2360509.0000\n",
            "Epoch 74/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5985557544960.0000 - mae: 2166461.2500 - val_loss: 7016372764672.0000 - val_mae: 2338923.0000\n",
            "Epoch 75/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5861014503424.0000 - mae: 2140560.0000 - val_loss: 6877246128128.0000 - val_mae: 2320625.0000\n",
            "Epoch 76/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5739103387648.0000 - mae: 2114574.5000 - val_loss: 6743465656320.0000 - val_mae: 2300736.2500\n",
            "Epoch 77/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5619642793984.0000 - mae: 2089025.5000 - val_loss: 6608476176384.0000 - val_mae: 2280497.2500\n",
            "Epoch 78/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5502305566720.0000 - mae: 2065244.7500 - val_loss: 6479257010176.0000 - val_mae: 2260367.0000\n",
            "Epoch 79/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5389814333440.0000 - mae: 2040545.5000 - val_loss: 6355943948288.0000 - val_mae: 2239790.2500\n",
            "Epoch 80/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5282817114112.0000 - mae: 2018219.3750 - val_loss: 6238445240320.0000 - val_mae: 2218079.2500\n",
            "Epoch 81/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5170950832128.0000 - mae: 1994245.2500 - val_loss: 6115672195072.0000 - val_mae: 2196753.0000\n",
            "Epoch 82/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5061562859520.0000 - mae: 1970762.2500 - val_loss: 5991316324352.0000 - val_mae: 2174197.5000\n",
            "Epoch 83/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4954092208128.0000 - mae: 1947676.8750 - val_loss: 5873438031872.0000 - val_mae: 2152789.5000\n",
            "Epoch 84/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4846186397696.0000 - mae: 1923872.3750 - val_loss: 5759189909504.0000 - val_mae: 2130777.7500\n",
            "Epoch 85/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4742257836032.0000 - mae: 1901414.8750 - val_loss: 5646231535616.0000 - val_mae: 2108561.7500\n",
            "Epoch 86/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4641446690816.0000 - mae: 1878566.3750 - val_loss: 5528730730496.0000 - val_mae: 2085409.5000\n",
            "Epoch 87/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4539079983104.0000 - mae: 1854858.1250 - val_loss: 5412873043968.0000 - val_mae: 2060837.8750\n",
            "Epoch 88/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4442382401536.0000 - mae: 1832637.2500 - val_loss: 5306849427456.0000 - val_mae: 2038440.0000\n",
            "Epoch 89/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4348386213888.0000 - mae: 1810495.3750 - val_loss: 5212744450048.0000 - val_mae: 2016759.6250\n",
            "Epoch 90/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4250483818496.0000 - mae: 1787580.7500 - val_loss: 5109749645312.0000 - val_mae: 1993530.0000\n",
            "Epoch 91/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4151445291008.0000 - mae: 1764221.7500 - val_loss: 5005940621312.0000 - val_mae: 1970120.0000\n",
            "Epoch 92/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4058451804160.0000 - mae: 1741046.3750 - val_loss: 4902409994240.0000 - val_mae: 1946292.0000\n",
            "Epoch 93/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3962592559104.0000 - mae: 1717244.8750 - val_loss: 4802200731648.0000 - val_mae: 1922650.8750\n",
            "Epoch 94/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3871277842432.0000 - mae: 1694256.1250 - val_loss: 4705444954112.0000 - val_mae: 1898947.2500\n",
            "Epoch 95/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3781420908544.0000 - mae: 1671300.6250 - val_loss: 4605079453696.0000 - val_mae: 1874119.2500\n",
            "Epoch 96/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3691606179840.0000 - mae: 1648205.5000 - val_loss: 4507258322944.0000 - val_mae: 1849556.0000\n",
            "Epoch 97/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3602922864640.0000 - mae: 1624553.2500 - val_loss: 4410889469952.0000 - val_mae: 1824673.5000\n",
            "Epoch 98/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3517693820928.0000 - mae: 1601717.8750 - val_loss: 4309509996544.0000 - val_mae: 1798140.7500\n",
            "Epoch 99/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 3428503781376.0000 - mae: 1576956.8750 - val_loss: 4214040559616.0000 - val_mae: 1771710.5000\n",
            "Epoch 100/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3341936492544.0000 - mae: 1553088.0000 - val_loss: 4127150047232.0000 - val_mae: 1747346.5000\n",
            "Epoch 101/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3261211344896.0000 - mae: 1530330.0000 - val_loss: 4043933745152.0000 - val_mae: 1723275.1250\n",
            "Epoch 102/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3181100924928.0000 - mae: 1506303.3750 - val_loss: 3958194307072.0000 - val_mae: 1699462.5000\n",
            "Epoch 103/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3102275272704.0000 - mae: 1483676.1250 - val_loss: 3870541479936.0000 - val_mae: 1675092.0000\n",
            "Epoch 104/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3023379890176.0000 - mae: 1460306.2500 - val_loss: 3785075720192.0000 - val_mae: 1650662.8750\n",
            "Epoch 105/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2948253614080.0000 - mae: 1437830.7500 - val_loss: 3705214599168.0000 - val_mae: 1627009.1250\n",
            "Epoch 106/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2874617102336.0000 - mae: 1415264.1250 - val_loss: 3627805573120.0000 - val_mae: 1603590.5000\n",
            "Epoch 107/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2805017870336.0000 - mae: 1394323.0000 - val_loss: 3554033532928.0000 - val_mae: 1582728.3750\n",
            "Epoch 108/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2737576869888.0000 - mae: 1373287.0000 - val_loss: 3476292632576.0000 - val_mae: 1560121.2500\n",
            "Epoch 109/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2669192413184.0000 - mae: 1352700.8750 - val_loss: 3405675757568.0000 - val_mae: 1539134.5000\n",
            "Epoch 110/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2605079592960.0000 - mae: 1332606.8750 - val_loss: 3333041160192.0000 - val_mae: 1516788.8750\n",
            "Epoch 111/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2541959249920.0000 - mae: 1312433.2500 - val_loss: 3267155460096.0000 - val_mae: 1495932.0000\n",
            "Epoch 112/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2480897523712.0000 - mae: 1292009.2500 - val_loss: 3198399283200.0000 - val_mae: 1473691.1250\n",
            "Epoch 113/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2422086565888.0000 - mae: 1272366.6250 - val_loss: 3130473054208.0000 - val_mae: 1451488.1250\n",
            "Epoch 114/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2364021932032.0000 - mae: 1253487.8750 - val_loss: 3072691011584.0000 - val_mae: 1431198.8750\n",
            "Epoch 115/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2307214016512.0000 - mae: 1234070.2500 - val_loss: 3006466097152.0000 - val_mae: 1408097.8750\n",
            "Epoch 116/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2253351550976.0000 - mae: 1215067.6250 - val_loss: 2941572612096.0000 - val_mae: 1384481.5000\n",
            "Epoch 117/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2199148036096.0000 - mae: 1197014.5000 - val_loss: 2885355307008.0000 - val_mae: 1363597.0000\n",
            "Epoch 118/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2150122520576.0000 - mae: 1180011.8750 - val_loss: 2830696972288.0000 - val_mae: 1342756.5000\n",
            "Epoch 119/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 2102316498944.0000 - mae: 1164227.0000 - val_loss: 2780482240512.0000 - val_mae: 1322485.8750\n",
            "Epoch 120/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2056837529600.0000 - mae: 1147850.1250 - val_loss: 2730677239808.0000 - val_mae: 1301938.1250\n",
            "Epoch 121/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2011859386368.0000 - mae: 1132739.1250 - val_loss: 2684083503104.0000 - val_mae: 1285110.3750\n",
            "Epoch 122/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1967583789056.0000 - mae: 1117087.1250 - val_loss: 2637943275520.0000 - val_mae: 1268237.1250\n",
            "Epoch 123/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1927671840768.0000 - mae: 1102956.6250 - val_loss: 2590931681280.0000 - val_mae: 1252482.1250\n",
            "Epoch 124/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1889000620032.0000 - mae: 1089707.1250 - val_loss: 2547580928000.0000 - val_mae: 1236708.2500\n",
            "Epoch 125/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1850754990080.0000 - mae: 1075818.2500 - val_loss: 2506723950592.0000 - val_mae: 1222780.8750\n",
            "Epoch 126/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1818896760832.0000 - mae: 1064515.8750 - val_loss: 2469087936512.0000 - val_mae: 1212174.8750\n",
            "Epoch 127/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1784887902208.0000 - mae: 1052484.8750 - val_loss: 2432338755584.0000 - val_mae: 1201208.0000\n",
            "Epoch 128/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1754370015232.0000 - mae: 1040973.5625 - val_loss: 2399304679424.0000 - val_mae: 1191187.1250\n",
            "Epoch 129/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1723344093184.0000 - mae: 1029295.7500 - val_loss: 2366624497664.0000 - val_mae: 1180707.6250\n",
            "Epoch 130/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1695786336256.0000 - mae: 1018669.1250 - val_loss: 2337486405632.0000 - val_mae: 1171806.1250\n",
            "Epoch 131/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1667112370176.0000 - mae: 1007937.2500 - val_loss: 2303740608512.0000 - val_mae: 1161847.8750\n",
            "Epoch 132/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1640060551168.0000 - mae: 997452.5000 - val_loss: 2274003255296.0000 - val_mae: 1153145.5000\n",
            "Epoch 133/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1616721346560.0000 - mae: 988282.0625 - val_loss: 2246765707264.0000 - val_mae: 1146259.2500\n",
            "Epoch 134/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1591519870976.0000 - mae: 977917.2500 - val_loss: 2221660438528.0000 - val_mae: 1139154.5000\n",
            "Epoch 135/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1569375649792.0000 - mae: 968809.6875 - val_loss: 2195060162560.0000 - val_mae: 1132003.1250\n",
            "Epoch 136/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1548557221888.0000 - mae: 960223.8125 - val_loss: 2171848359936.0000 - val_mae: 1125079.8750\n",
            "Epoch 137/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1528807948288.0000 - mae: 952392.0625 - val_loss: 2152445509632.0000 - val_mae: 1118998.1250\n",
            "Epoch 138/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1509936201728.0000 - mae: 945269.0625 - val_loss: 2127832154112.0000 - val_mae: 1111627.0000\n",
            "Epoch 139/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1491166035968.0000 - mae: 938038.3125 - val_loss: 2107238907904.0000 - val_mae: 1104723.0000\n",
            "Epoch 140/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1474070183936.0000 - mae: 931870.6875 - val_loss: 2085873516544.0000 - val_mae: 1097970.0000\n",
            "Epoch 141/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1457904156672.0000 - mae: 924765.6875 - val_loss: 2067955843072.0000 - val_mae: 1093218.8750\n",
            "Epoch 142/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1441167966208.0000 - mae: 918431.4375 - val_loss: 2050816344064.0000 - val_mae: 1088509.5000\n",
            "Epoch 143/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1427106562048.0000 - mae: 913071.7500 - val_loss: 2035706757120.0000 - val_mae: 1084330.1250\n",
            "Epoch 144/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1412241555456.0000 - mae: 906954.0625 - val_loss: 2019961602048.0000 - val_mae: 1080045.7500\n",
            "Epoch 145/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1399399776256.0000 - mae: 901817.3750 - val_loss: 2006873669632.0000 - val_mae: 1075512.8750\n",
            "Epoch 146/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1385763307520.0000 - mae: 896384.5000 - val_loss: 1989384339456.0000 - val_mae: 1071043.5000\n",
            "Epoch 147/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1372758081536.0000 - mae: 891064.5000 - val_loss: 1974527459328.0000 - val_mae: 1067130.1250\n",
            "Epoch 148/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1361125703680.0000 - mae: 886323.1250 - val_loss: 1962047307776.0000 - val_mae: 1064139.8750\n",
            "Epoch 149/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 1350867091456.0000 - mae: 882240.3125 - val_loss: 1948774694912.0000 - val_mae: 1059852.1250\n",
            "Epoch 150/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1339204829184.0000 - mae: 877769.8125 - val_loss: 1937104044032.0000 - val_mae: 1056898.8750\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2430411735040.0000 - mae: 1220097.6250\n",
            "Test MAE: 1220097.625\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    }
  ]
}